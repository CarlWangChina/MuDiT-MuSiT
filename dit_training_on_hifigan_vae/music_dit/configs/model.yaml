model:
    vae:
        frame_size: 150
        embedding_dim: 128
    clap:
        embedding_dim: 512
    lyrics:
        vocab_size: 100300
        padding_token: 100287
    dit:
        input_dim: ${..vae.embedding_dim}
        hidden_dim: 1024
        num_layers: 24
        num_heads: 16
        dropout: 0.1
        use_causality: false
        use_cross_attention: true
        use_rpr: true
        context_dim: 1024
        pos_embedding: "RoPE"
        max_position: 10000
        use_learned_variance: true
        max_timestep_period: 2000
    sampler:
        beta_start: 1e-4
        beta_end: 0.02
        beta_schedule: "linear"
        timestep_spacing: "leading"
        num_training_timesteps: 1000
        num_inference_timesteps: 20
        dynamic_thresholding_ratio: 0.995
        clip_sample_range: null
    loss:
        loss_type: "mse"

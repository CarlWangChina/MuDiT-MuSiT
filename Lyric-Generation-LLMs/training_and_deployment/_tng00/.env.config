#!/usr/bin/env bash

# MODIFY THIS TO MATCH YOUR SETUP
export PROJECT_ROOT="/home/carl/projects/ama-prof-divi-libai"

# default docker image to run Qwen
export DEF_DOCKER_IMG="qwenllm/qwen:cu117"
# root path for models on host
export MODELS_RT_PATH="$PROJECT_ROOT/models"
# default base model path relative to $MODELS_RT_PATH
export DEF_BASE_MODEL="qwen/Qwen-14B-Chat-Int4"

# base model path on host, to be mounted to container
export H_BASE_MODEL="$MODELS_RT_PATH/$DEF_BASE_MODEL"
# the mounted path on container, for base model
export C_BASE_MODEL="/data/shared/Qwen/base-model"

# training data
export HP_TRNG_DATA="$PROJECT_ROOT/_tng00/data/ftip"
export CP_TRNG_DATA="/data/shared/Qwen/trng-input"

# finetune output
export HP_FT_OUTPUT="$PROJECT_ROOT/_tng00/data/ftop"
# WARNING: the output dir root name 'output_qwen' is hardcoded in
# all original finetune sctipts, so it's better to keep it unchanged,
# or you MUST write your own finetune scripts, modify the output dir
# name accordingly, mount and run them in docker run command.
export CP_FT_OUTPUT="/data/shared/Qwen/output_qwen"

# checkpoint infer's io
export HP_CKPT_IFIO="$PROJECT_ROOT/_tng00/data/ciio"
export CP_CKPT_IFIO="/data/shared/Qwen/ckpt-if-io"

# custom scripts
export HP_CUST_SCRS="$PROJECT_ROOT/_tng00/scripts/exec_ic"
export CP_CUST_SCRS="/data/shared/Qwen/cs-scripts"